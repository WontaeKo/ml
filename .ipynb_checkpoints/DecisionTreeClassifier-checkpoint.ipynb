{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4e49c48",
   "metadata": {},
   "source": [
    "# [`sklearn.tree`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.tree \"sklearn.tree\").DecisionTreeClassifier[](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn-tree-decisiontreeclassifier \"Permalink to this heading\")\n",
    "\n",
    "_class_ sklearn.tree.DecisionTreeClassifier(_*_,  _criterion='gini'_,  _splitter='best'_,  _max_depth=None_,  _min_samples_split=2_,  _min_samples_leaf=1_,  _min_weight_fraction_leaf=0.0_,  _max_features=None_,  _random_state=None_,  _max_leaf_nodes=None_,  _min_impurity_decrease=0.0_,  _class_weight=None_,  _ccp_alpha=0.0_)[[source]](https://github.com/scikit-learn/scikit-learn/blob/7db5b6a98/sklearn/tree/_classes.py#L595)[¶](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier \"Permalink to this definition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7460d03d",
   "metadata": {},
   "source": [
    "Parameters:\n",
    "criterion{“gini”, “entropy”, “log_loss”}, default=”gini”\n",
    "The function to measure the quality of a split. Supported criteria are “gini” for the Gini impurity and “log_loss” and “entropy” both for the Shannon information gain, see Mathematical formulation.\n",
    "\n",
    "splitter{“best”, “random”}, default=”best”\n",
    "The strategy used to choose the split at each node. Supported strategies are “best” to choose the best split and “random” to choose the best random split.\n",
    "\n",
    "max_depthint, default=None\n",
    "The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.\n",
    "\n",
    "min_samples_splitint or float, default=2\n",
    "The minimum number of samples required to split an internal node:\n",
    "\n",
    "If int, then consider min_samples_split as the minimum number.\n",
    "\n",
    "If float, then min_samples_split is a fraction and ceil(min_samples_split * n_samples) are the minimum number of samples for each split.\n",
    "\n",
    "Changed in version 0.18: Added float values for fractions.\n",
    "\n",
    "min_samples_leafint or float, default=1\n",
    "The minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least min_samples_leaf training samples in each of the left and right branches. This may have the effect of smoothing the model, especially in regression.\n",
    "\n",
    "If int, then consider min_samples_leaf as the minimum number.\n",
    "\n",
    "If float, then min_samples_leaf is a fraction and ceil(min_samples_leaf * n_samples) are the minimum number of samples for each node.\n",
    "\n",
    "Changed in version 0.18: Added float values for fractions.\n",
    "\n",
    "min_weight_fraction_leaffloat, default=0.0\n",
    "The minimum weighted fraction of the sum total of weights (of all the input samples) required to be at a leaf node. Samples have equal weight when sample_weight is not provided.\n",
    "\n",
    "max_featuresint, float or {“auto”, “sqrt”, “log2”}, default=None\n",
    "The number of features to consider when looking for the best split:\n",
    "\n",
    "If int, then consider max_features features at each split.\n",
    "\n",
    "If float, then max_features is a fraction and max(1, int(max_features * n_features_in_)) features are considered at each split.\n",
    "\n",
    "If “auto”, then max_features=sqrt(n_features).\n",
    "\n",
    "If “sqrt”, then max_features=sqrt(n_features).\n",
    "\n",
    "If “log2”, then max_features=log2(n_features).\n",
    "\n",
    "If None, then max_features=n_features.\n",
    "\n",
    "Deprecated since version 1.1: The \"auto\" option was deprecated in 1.1 and will be removed in 1.3.\n",
    "Note: the search for a split does not stop until at least one valid partition of the node samples is found, even if it requires to effectively inspect more than max_features features.\n",
    "\n",
    "random_stateint, RandomState instance or None, default=None\n",
    "Controls the randomness of the estimator. The features are always randomly permuted at each split, even if splitter is set to \"best\". When max_features < n_features, the algorithm will select max_features at random at each split before finding the best split among them. But the best found split may vary across different runs, even if max_features=n_features. That is the case, if the improvement of the criterion is identical for several splits and one split has to be selected at random. To obtain a deterministic behaviour during fitting, random_state has to be fixed to an integer. See Glossary for details.\n",
    "\n",
    "max_leaf_nodesint, default=None\n",
    "Grow a tree with max_leaf_nodes in best-first fashion. Best nodes are defined as relative reduction in impurity. If None then unlimited number of leaf nodes.\n",
    "\n",
    "min_impurity_decreasefloat, default=0.0\n",
    "A node will be split if this split induces a decrease of the impurity greater than or equal to this value.\n",
    "\n",
    "The weighted impurity decrease equation is the following:\n",
    "\n",
    "N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
    "                    - N_t_L / N_t * left_impurity)\n",
    "where N is the total number of samples, N_t is the number of samples at the current node, N_t_L is the number of samples in the left child, and N_t_R is the number of samples in the right child.\n",
    "\n",
    "N, N_t, N_t_R and N_t_L all refer to the weighted sum, if sample_weight is passed.\n",
    "\n",
    "New in version 0.19.\n",
    "\n",
    "class_weightdict, list of dict or “balanced”, default=None\n",
    "Weights associated with classes in the form {class_label: weight}. If None, all classes are supposed to have weight one. For multi-output problems, a list of dicts can be provided in the same order as the columns of y.\n",
    "\n",
    "Note that for multioutput (including multilabel) weights should be defined for each class of every column in its own dict. For example, for four-class multilabel classification weights should be [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of [{1:1}, {2:5}, {3:1}, {4:1}].\n",
    "\n",
    "The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as n_samples / (n_classes * np.bincount(y))\n",
    "\n",
    "For multi-output, the weights of each column of y will be multiplied.\n",
    "\n",
    "Note that these weights will be multiplied with sample_weight (passed through the fit method) if sample_weight is specified.\n",
    "\n",
    "ccp_alphanon-negative float, default=0.0\n",
    "Complexity parameter used for Minimal Cost-Complexity Pruning. The subtree with the largest cost complexity that is smaller than ccp_alpha will be chosen. By default, no pruning is performed. See Minimal Cost-Complexity Pruning for details.\n",
    "\n",
    "New in version 0.22."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cbf1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warning\n",
    "import pandas as pd\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# DecisionTree Classifier 생성\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "# 붓꽃 데이터를 로딩하고, 학습과 테스트 데이터 셋으로 분리\n",
    "iris_data = load_iris()\n",
    "X_train, x_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size = 0.2, random_state=11)\n",
    "\n",
    "# DecisionTreeClassifier 학습\n",
    "dt_clf.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "# export_graphvix()의 호출 결과로 out_file로 지정된 tree.dot 파일을 생성함.\n",
    "export_graphviz(dt_clf, out_file=\"tree.dot\", class_names = iris_data.target_names, \\\n",
    "features_names = iris_data.features_names, impurity=True, filled=True)\n",
    "\n",
    "import graphviz\n",
    "\n",
    "# 위에서 생성된 tree.dot 파일을 Graphviz 읽어서 Jupyter Notebook 상에서 시각화\n",
    "with open(\"tree.dot\") as f:\n",
    "    dot_graph = f.read()\n",
    "graphviz.Source(dot_graph)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20011794",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_clf.feature_imortances_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c768856",
   "metadata": {},
   "source": [
    "### export_graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f38d2cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-01T04:48:44.175052Z",
     "start_time": "2023-02-01T04:48:42.326108Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in c:\\users\\wontae2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.20.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install graphviz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b12fca65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-01T05:10:50.648085Z",
     "start_time": "2023-02-01T05:10:50.374271Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'tree.dot'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgraphviz\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtree.dot\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      4\u001b[0m     f\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m      5\u001b[0m graphviz\u001b[38;5;241m.\u001b[39mSource(dot_graph)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    277\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m     )\n\u001b[1;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tree.dot'"
     ]
    }
   ],
   "source": [
    "import graphviz\n",
    "\n",
    "with open('tree.dot') as f:\n",
    "    f.read()\n",
    "graphviz.Source(dot_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba11710",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
